{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary class version of agaadha-nama\n",
    "- Added 'None' support for N_SAMPLE for processing all images in selected class\n",
    "- Added LABEL_CLASSES support for selecting classes to categorize by name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as path\n",
    "from scipy import misc, stats\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import pathlib\n",
    "\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.utils import to_categorical # For keras > 2.0\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'dataset/google/*/*'\n",
    "\n",
    "\n",
    "N_CLASSES = 5 # how many asanas to classify\n",
    "LABEL_CLASSES = ['Urdhva+Dhanurasana'] # which asanas to classify\n",
    "\n",
    "N_SAMPLE = 600 #None # how many to sample from each class (classes w/ <N will be dropped)\n",
    "                # if None, automatically selects all observations from each class\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "\n",
    "IMG_SIZE = (300,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filepathsdf(path, n_classes=None, label_classes=None, n_sample=None):\n",
    "    \"\"\" Create dataframe of image labels and file-locations.\n",
    "    \n",
    "        Input:  - path to glob for full path of each file.\n",
    "                    contents of path should be the result of \n",
    "                        scrape_images_search.py (image_search)\n",
    "                    ignores any metadata files (*.json)\n",
    "                - n_classes number of classes to use in classification\n",
    "                    if None, takes the number of classes found in path\n",
    "                - label_classes specific labels of classes to use in classification\n",
    "                    if None, takes the list of all classes found in path\n",
    "                Note that the min of n_classes and len(label_classes) takes precedence\n",
    "                i.e. if   len(label_classes)<=n_classes, use label_classes\n",
    "                     elif len(label_classes)>n_classes, sample n_classes from label_classes\n",
    "                - n_sample number of images per class to consider, \n",
    "                    Note that any classes w/ < n_sample images will be disregarded. \n",
    "                    If None, takes all images from each class\n",
    "        Output:  - dataframe of labels & paths of all mages to be used in classification\n",
    "    \"\"\"\n",
    "    \n",
    "    # PATH -> DF\n",
    "    filepaths = glob.glob(path)\n",
    "    filepaths = [x for x in filepaths if os.path.splitext(x)[1]!='.json']\n",
    "    filepaths_df = pd.DataFrame({'path': filepaths,\\\n",
    "                            'label': [x.split('/')[2] for x in filepaths]})\n",
    "\n",
    "    print(\"Found %d classes w/ %d images, total.\" % (len(filepaths_df.label.drop_duplicates()),\\\n",
    "                                                 len(filepaths_df.path)))\n",
    "    print\n",
    "    \n",
    "    if not n_classes:\n",
    "        n_classes = len(filepaths_df.label.drop_duplicates())\n",
    "    if not label_classes:\n",
    "        label_classes = filepaths_df.label.drop_duplicates().tolist()\n",
    "        \n",
    "    if len(label_classes) <= n_classes:\n",
    "        # use label_classes\n",
    "        classes = label_classes\n",
    "    elif len(label_classes) > n_classes:\n",
    "        # sample n_classes from label_clases\n",
    "        classes = random.sample(label_classes,n_classes)\n",
    "\n",
    "    filepaths_df = filepaths_df[filepaths_df['label'].isin(classes)]\n",
    "    cnt_df = filepaths_df.groupby('label', as_index=False)['path'].count(\\\n",
    "                                                ).sort_values(by=['path'], ascending=False)\n",
    "    \n",
    "    # subset DF to only those containing >= n_sample\n",
    "    # & sample N_SAMPLE per group\n",
    "    if n_sample: \n",
    "        lbls = cnt_df[cnt_df.path>=n_sample].label.tolist()\n",
    "        mask = filepaths_df['label'].isin(lbls)\n",
    "        filepaths_df = filepaths_df[mask]\n",
    "        filepaths_df = filepaths_df.groupby('label').apply(lambda x: \\\n",
    "                                        x.sample(N_SAMPLE)).reset_index(drop=True)\n",
    "    \n",
    "    classes_sample = filepaths_df.label.drop_duplicates().tolist()\n",
    "    \n",
    "    print(\"Classifying %d classes w/ %d images, total: %s \" \\\n",
    "          % (len(classes_sample), np.sum(cnt_df.path), ', '.join(classes_sample)))\n",
    "    print\n",
    "    return(filepaths_df) \n",
    "\n",
    "def load_imgs(df):\n",
    "    \"\"\" Load files from  dataframe of image labels and file-locations.\n",
    "        Drops from dataframe rows pertaining to failed image loads\n",
    "    \n",
    "        Input:  - dataframe of labels & paths of all mages to be used in classification\n",
    "        Output: - dataframe of labels & paths of all mages to be used in classification\n",
    "                - list of image arrays\n",
    "    \"\"\"\n",
    "    images=[]\n",
    "    for i in df.index:\n",
    "        path = df.path[i]\n",
    "        try:\n",
    "            images.append(misc.imread(path))\n",
    "        except:\n",
    "            print \"Failed to read in: %s, Dropping from dataframe\" % path\n",
    "            df = df.drop(i)\n",
    "    print(\"Number of images loaded: %d\" %len(images))\n",
    "    print(\"Number of images in returned df: %d\" % df.shape[0])\n",
    "    print\n",
    "    return(df, images)\n",
    "\n",
    "def preproc_imgs(images, img_size):\n",
    "    \"\"\" Preprocess list of image arrays \n",
    "        # (1) Scale image arrays s.t range is between 0 and 1 instea dof 0 and 255\n",
    "        # (2) Resize to be of dim IMG_SIZE (width,height)\n",
    "        # When the normType is NORM_MINMAX, cv::normalize normalizes _src in such a way that \n",
    "        #   the min value of dst is alpha and max value of dst is beta. cv::normalize does its magic \n",
    "        #   using only scales and shifts (i.e. adding constants and multiplying by constants).\n",
    "        # (3) Drop fourth dimmension for PNG images\n",
    "        # (4) create 3rd dim for greay scale imges\n",
    "    \n",
    "        Input:  - images list of image arrays\n",
    "                - img_size tuple of new image size\n",
    "        Output: - images list of preprocessed image arrays, with the above modifications\n",
    "    \"\"\"\n",
    "\n",
    "    i=random.randint(0, len(images))\n",
    "    \n",
    "    images_sc = [None] * len(images)\n",
    "    for j in range(len(images)):\n",
    "        if j % 250 == 0:\n",
    "            print \"Preprocessed %d images...\" % j\n",
    "        if images[j].all()==None:\n",
    "            images_sc[j]=None\n",
    "        else:\n",
    "            try:\n",
    "                temp = images[j]\n",
    "                if len(temp.shape) > 2 and temp.shape[2] == 4: # PNG rgb images have 4 channels\n",
    "                    temp = cv2.cvtColor(temp, cv2.COLOR_BGRA2BGR)\n",
    "                elif len(temp.shape) > 2 and temp.shape[2] == 2: # PNG grsc images have 2 channels\n",
    "                    temp = np.stack((temp[:,:,0],)*3, -1)\n",
    "                elif len(temp.shape) == 2: # grsc images have 1 channel\n",
    "                    temp = np.stack((temp,)*3, -1)\n",
    "                temp = cv2.resize(temp.astype('uint8'), dsize=IMG_SIZE)\n",
    "                temp = cv2.normalize(temp, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, \\\n",
    "                                     dtype=cv2.CV_32F, dst=None)\n",
    "                images_sc[j] = temp\n",
    "            except:\n",
    "                print \"Unexpected error:\", sys.exc_info()[0]\n",
    "\n",
    "    print \"Preprocessed %d images!\" % images_sc.shape[0]\n",
    "    print\n",
    "    return (images_sc)\n",
    "\n",
    "def create_testtrain(images, df, train_test_split):\n",
    "    \"\"\" from dataframe image list, create x_ & y_ train and x_ & y_ test.\n",
    "        \n",
    "        Input:  - images list of preprocessed image arrays\n",
    "                - df dataframe of labels & paths of all mages to be used in classification\n",
    "                = train_test_split float = proportion of images to set aside for training\n",
    "        Output: - x_train, y_train, x_test, y_test\n",
    "    \"\"\"\n",
    "    n_images = len(images_sc)\n",
    "    labels = df.label.tolist()\n",
    "    paths = df.path.tolist()\n",
    "\n",
    "    # encode class values as integers\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(labels)\n",
    "    encoded_Y = encoder.transform(labels)\n",
    "    dummy_y = to_categorical(encoded_Y)\n",
    "\n",
    "    split_index = int(train_test_split * n_images)\n",
    "    shuffled_indices = np.random.permutation(n_images)\n",
    "    train_indices = shuffled_indices[0:split_index]\n",
    "    test_indices = shuffled_indices[split_index:]\n",
    "\n",
    "    # Split the images and the labels\n",
    "    x_train = np.array([images_sc[i] for i in train_indices])\n",
    "    y_train = np.array([dummy_y[i] for i in train_indices])\n",
    "    paths_train = [paths[i] for i in train_indices]\n",
    "    print(\"... of which %d are train images loaded and %d train labels\" % \\\n",
    "          (x_train.shape[0],y_train.shape[0]))\n",
    "    print\n",
    "\n",
    "    x_test = np.array([images_sc[i] for i in test_indices])\n",
    "    y_test = np.array([dummy_y[i] for i in test_indices])\n",
    "    paths_test = [paths[i] for i in test_indices]\n",
    "    print(\"... of which %d test images loaded and %d test labels\" % \\\n",
    "          (x_test.shape[0],y_test.shape[0]))\n",
    "    \n",
    "    return(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 149 classes w/ 71379 images, total.\n",
      "\n",
      "Classifying 1 classes w/ 562 images, total: Urdhva+Dhanurasana \n",
      "\n",
      "\n",
      "Number of images loaded: 562\n",
      "Number of images in returned df: 562\n",
      "Preprocessed 0 images...\n",
      "Preprocessed 250 images...\n",
      "Preprocessed 500 images...\n"
     ]
    }
   ],
   "source": [
    "filepaths_df = create_filepathsdf(path = PATH, label_classes= LABEL_CLASSES)\n",
    "filepaths_df, images = load_imgs(df = filepaths_df)\n",
    "images_sc = preproc_imgs(images = images, img_size = IMG_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... of which 449 are train images loaded and 449 train labels\n",
      "\n",
      "... of which 113 train images loaded and 113 train labels\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = create_testtrain(images = images_sc, \\\n",
    "                                                    df = filepaths_df, \\\n",
    "                                                    train_test_split = TRAIN_TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "image_size = x_train[0].shape\n",
    "n_classes = y_train.shape[1]\n",
    "# model = cnn(size=image_size, n_layers=N_LAYERS, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 86\n",
    "\n",
    "img_rows, img_cols = IMG_SIZE\n",
    "\n",
    "nb_filters_1 = 32 \n",
    "nb_filters_2 = 64 \n",
    "nb_filters_3 = 128 \n",
    "\n",
    "nb_conv = 3 # kernel_size dim\n",
    "nb_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(filters = nb_filters_1, \n",
    "                 kernel_size = (nb_conv,nb_conv),\n",
    "                 padding = 'Same', \n",
    "                 activation ='relu', \n",
    "                 input_shape = image_size))\n",
    "model1.add(Conv2D(filters = nb_filters_1, \n",
    "                 kernel_size = (nb_conv,nb_conv),\n",
    "                 padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Conv2D(filters = nb_filters_2, \n",
    "                 kernel_size = (nb_conv,nb_conv),\n",
    "                 padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model1.add(Conv2D(filters = nb_filters_2, \n",
    "                 kernel_size = (nb_conv,nb_conv),\n",
    "                 padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(256, activation = \"relu\"))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(nb_classes, activation = \"softmax\"))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model1.compile(optimizer = optimizer , \\\n",
    "              loss = \"categorical_crossentropy\", \\\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL TRAINING ##\n",
    "# Training Hyperparamters\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "# Early stopping callback\n",
    "PATIENCE = 10\n",
    "early_stopping = EarlyStopping(monitor='loss', min_delta=0, patience=PATIENCE, verbose=0, mode='auto')\n",
    "\n",
    "# TensorBoard callback\n",
    "LOG_DIRECTORY_ROOT = 'logdir'\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "log_dir = \"{}/run-{}/\".format(LOG_DIRECTORY_ROOT, now)\n",
    "tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, write_images=True)\n",
    "\n",
    "# Place the callbacks in a list\n",
    "callbacks = [early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model1.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,\\\n",
    "          callbacks=callbacks, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "\n",
    "MODEL_DIRECTORY_ROOT = 'modeldir'\n",
    "model_dir = \"{}/run-{}/\".format(MODEL_DIRECTORY_ROOT, now)\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    " \n",
    "save_model(model1, model_dir+'model.h5', overwrite=True,include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL EVALUATION ##\n",
    "# Make a prediction on the test set\n",
    "test_predictions = model1.predict(x_test)\n",
    "test_predictions = np.round(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x_test.shape\n",
    "print test_predictions.shape\n",
    "print stats.describe(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_incorrect_labels(x_data, y_real, y_predicted):\n",
    "    # INPUTS\n",
    "    # x_data      - images\n",
    "    # y_data      - ground truth labels\n",
    "    # y_predicted - predicted label\n",
    "    count = 0\n",
    "    figure = plt.figure()\n",
    "    incorrect_label_indices = (y_real != y_predicted)\n",
    "    y_real = y_real[incorrect_label_indices]\n",
    "    y_predicted = y_predicted[incorrect_label_indices]\n",
    "    x_data = x_data[incorrect_label_indices, :, :, :]\n",
    "\n",
    "    maximum_square = np.ceil(np.sqrt(x_data.shape[0]))\n",
    "\n",
    "    for i in range(x_data.shape[0]):\n",
    "        count += 1\n",
    "        figure.add_subplot(maximum_square, maximum_square, count)\n",
    "        plt.imshow(x_data[i, :, :, :])\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Predicted: \" + str(int(y_predicted[i])) + \", Real: \" + str(int(y_real[i])), fontsize=10)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "visualize_incorrect_labels(x_test, y_test, np.asarray(test_predictions).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
