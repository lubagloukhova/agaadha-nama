{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary class version of agaadha-nama\n",
    "- Added 'None' support for N_SAMPLE for processing all images in selected class\n",
    "- Added LABEL_CLASSES support for selecting classes to categorize by name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as path\n",
    "from scipy import misc, stats\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import pathlib\n",
    "\n",
    "from keras.models import Sequential, save_model, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.utils import to_categorical # For keras > 2.0\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'dataset/google/*/*'\n",
    "\n",
    "\n",
    "N_CLASSES = 5 # how many asanas to classify\n",
    "LABEL_CLASSES = ['Urdhva+Dhanurasana'] # which asanas to classify\n",
    "\n",
    "N_SAMPLE = None  #None # how many to sample from each class (classes w/ <N will be dropped)\n",
    "                # if None, automatically selects all observations from each class\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "\n",
    "IMG_SIZE = (300,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filepathsdf(path, n_classes=None, label_classes=None, n_sample=None):\n",
    "    \"\"\" Create dataframe of image labels and file-locations.\n",
    "    \n",
    "        Input:  - path to glob for full path of each file.\n",
    "                    contents of path should be the result of \n",
    "                        scrape_images_search.py (image_search)\n",
    "                    ignores any metadata files (*.json)\n",
    "                - n_classes number of classes to use in classification\n",
    "                    if None, takes the number of classes found in path\n",
    "                - label_classes specific labels of classes to use in classification\n",
    "                    if None, takes the list of all classes found in path\n",
    "                Note that the min of n_classes and len(label_classes) takes precedence\n",
    "                i.e. if   len(label_classes)<=n_classes, use label_classes\n",
    "                     elif len(label_classes)>n_classes, sample n_classes from label_classes\n",
    "                - n_sample number of images per class to consider, \n",
    "                    Note that any classes w/ < n_sample images will be disregarded. \n",
    "                    If None, takes all images from each class\n",
    "        Output:  - dataframe of labels & paths of all mages to be used in classification\n",
    "    \"\"\"\n",
    "    \n",
    "    # PATH -> DF\n",
    "    filepaths = glob.glob(path)\n",
    "    filepaths = [x for x in filepaths if os.path.splitext(x)[1]!='.json']\n",
    "    filepaths_df = pd.DataFrame({'path': filepaths,\\\n",
    "                                 'label': [x.split('/')[2] for x in filepaths]})\n",
    "\n",
    "    print(\"Found %d classes w/ %d images, total.\" % (len(filepaths_df.label.drop_duplicates()),\\\n",
    "                                                     len(filepaths_df.path)))\n",
    "    print\n",
    "    \n",
    "    if not n_classes:\n",
    "        n_classes = len(filepaths_df.label.drop_duplicates())\n",
    "    if not label_classes:\n",
    "        label_classes = filepaths_df.label.drop_duplicates().tolist()\n",
    "        \n",
    "    if len(label_classes) <= n_classes:\n",
    "        # use label_classes\n",
    "        classes = label_classes\n",
    "    elif len(label_classes) > n_classes:\n",
    "        # sample n_classes from label_clases\n",
    "        classes = random.sample(label_classes,n_classes)\n",
    "\n",
    "    filepaths_df_1 = filepaths_df[filepaths_df['label'].isin(classes)]\n",
    "    filepaths_df_0 = filepaths_df[~filepaths_df['label'].isin(classes)]\n",
    "\n",
    "    \n",
    "    # subset DF to only those containing >= n_sample\n",
    "    # & sample N_SAMPLE per group\n",
    "    if n_sample: \n",
    "        lbls = cnt_df[cnt_df.path>=n_sample].label.tolist()\n",
    "        mask = filepaths_df['label'].isin(lbls)\n",
    "        filepaths_df_1 = filepaths_df[mask]\n",
    "        filepaths_df_1 = filepaths_df_1.groupby('label').apply(lambda x: \\\n",
    "                                        x.sample(n_sample)).reset_index(drop=True)\n",
    "    else:\n",
    "        n_sample = len(filepaths_df_1.path)\n",
    "        \n",
    "    # if only one class (i.e. model is hd-not-hd)\n",
    "    # sample same number of images from all images for negative class\n",
    "    if len(classes)==1:\n",
    "        filepaths_df_0 = filepaths_df_0.sample(n_sample)\n",
    "        filepaths_df_0.label = \"not_\"+LABEL_CLASSES[0]\n",
    "        filepaths_df_1 = filepaths_df_1.append(filepaths_df_0)\n",
    "    \n",
    "    cnt_df = filepaths_df_1.groupby('label', as_index=False)['path'].count(\\\n",
    "                                                ).sort_values(by=['path'], ascending=False)\n",
    "    cnt_str = ' '.join(cnt_df.to_string(header=False,\n",
    "                  index=False,\n",
    "                  index_names=False).split())\n",
    "   \n",
    "    print(\"Classifying %d classes w/ %d images, total:\" \\\n",
    "          % (len(cnt_df.label), sum(cnt_df.path) ))\n",
    "    print(\"\\t\"+cnt_str)\n",
    "    \n",
    "    print\n",
    "    return(filepaths_df_1) \n",
    "\n",
    "def load_imgs(df):\n",
    "    \"\"\" Load files from  dataframe of image labels and file-locations.\n",
    "        Drops from dataframe rows pertaining to failed image loads\n",
    "    \n",
    "        Input:  - dataframe of labels & paths of all mages to be used in classification\n",
    "        Output: - dataframe of labels & paths of all mages to be used in classification\n",
    "                - list of image arrays\n",
    "    \"\"\"\n",
    "    images=[]\n",
    "    for i in df.index:\n",
    "        path = df.path[i]\n",
    "        try:\n",
    "            images.append(misc.imread(path))\n",
    "        except:\n",
    "            print \"Failed to read in: %s, Dropping from dataframe\" % path\n",
    "            df = df.drop(i)\n",
    "    print(\"Loaded:\" )    \n",
    "    print(\"\\t %d images!\" %len(images))\n",
    "    print\n",
    "    return(df, images)\n",
    "\n",
    "def preproc_imgs(images, img_size):\n",
    "    \"\"\" Preprocess list of image arrays \n",
    "        # (1) Scale image arrays s.t range is between 0 and 1 instea dof 0 and 255\n",
    "        # (2) Resize to be of dim IMG_SIZE (width,height)\n",
    "        # When the normType is NORM_MINMAX, cv::normalize normalizes _src in such a way that \n",
    "        #   the min value of dst is alpha and max value of dst is beta. cv::normalize does its magic \n",
    "        #   using only scales and shifts (i.e. adding constants and multiplying by constants).\n",
    "        # (3) Drop fourth dimmension for PNG images\n",
    "        # (4) create 3rd dim for greay scale imges\n",
    "    \n",
    "        Input:  - images list of image arrays\n",
    "                - img_size tuple of new image size\n",
    "        Output: - images list of preprocessed image arrays, with the above modifications\n",
    "    \"\"\"\n",
    "\n",
    "    i=random.randint(0, len(images))\n",
    "    \n",
    "    images_sc = [None] * len(images)\n",
    "    print \"Preprocessed\"\n",
    "    for j in range(len(images)):\n",
    "        if j % 250 == 0:\n",
    "            print \"\\t %d images...\" % j\n",
    "        if images[j].all()==None:\n",
    "            images_sc[j]=None\n",
    "        else:\n",
    "            try:\n",
    "                temp = images[j]\n",
    "                if len(temp.shape) > 2 and temp.shape[2] == 4: # PNG rgb images have 4 channels\n",
    "                    temp = cv2.cvtColor(temp, cv2.COLOR_BGRA2BGR)\n",
    "                elif len(temp.shape) > 2 and temp.shape[2] == 2: # PNG grsc images have 2 channels\n",
    "                    temp = np.stack((temp[:,:,0],)*3, -1)\n",
    "                elif len(temp.shape) == 2: # grsc images have 1 channel\n",
    "                    temp = np.stack((temp,)*3, -1)\n",
    "                temp = cv2.resize(temp.astype('uint8'), dsize=IMG_SIZE)\n",
    "                temp = cv2.normalize(temp, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, \\\n",
    "                                     dtype=cv2.CV_32F, dst=None)\n",
    "                images_sc[j] = temp\n",
    "            except:\n",
    "                print \"Unexpected error:\", sys.exc_info()[0]\n",
    "\n",
    "    print \"\\t %d images!\" % len(images_sc)\n",
    "    print\n",
    "    return (images_sc)\n",
    "\n",
    "def create_testtrain(images, df, train_test_split):\n",
    "    \"\"\" from dataframe image list, create x_ & y_ train and x_ & y_ test.\n",
    "        \n",
    "        Input:  - images list of preprocessed image arrays\n",
    "                - df dataframe of labels & paths of all mages to be used in classification\n",
    "                = train_test_split float = proportion of images to set aside for training\n",
    "        Output: - x_train, y_train, x_test, y_test\n",
    "    \"\"\"\n",
    "    n_images = len(images_sc)\n",
    "    labels = df.label.tolist()\n",
    "    paths = df.path.tolist()\n",
    "\n",
    "    # encode class values as integers\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(labels)\n",
    "    encoded_Y = encoder.transform(labels)\n",
    "    dummy_y = to_categorical(encoded_Y)\n",
    "\n",
    "    split_index = int(train_test_split * n_images)\n",
    "    shuffled_indices = np.random.permutation(n_images)\n",
    "    train_indices = shuffled_indices[0:split_index]\n",
    "    test_indices = shuffled_indices[split_index:]\n",
    "    \n",
    "    print(\"Split dataset:\")\n",
    "\n",
    "    # Split the images and the labels\n",
    "    x_train = np.array([images_sc[i] for i in train_indices])\n",
    "    y_train = np.array([dummy_y[i] for i in train_indices])\n",
    "    paths_train = [paths[i] for i in train_indices]\n",
    "    print(\"\\t %d train images; %d train labels\" % \\\n",
    "          (x_train.shape[0],y_train.shape[0]))\n",
    "    print\n",
    "\n",
    "    x_test = np.array([images_sc[i] for i in test_indices])\n",
    "    y_test = np.array([dummy_y[i] for i in test_indices])\n",
    "    paths_test = [paths[i] for i in test_indices]\n",
    "    print(\"\\t %d test images; %d test labels\" % \\\n",
    "          (x_test.shape[0],y_test.shape[0]))\n",
    "    \n",
    "    return(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      "\t 1124 images!\n",
      "\n",
      "Preprocessed\n",
      "\t 0 images...\n",
      "\t 250 images...\n",
      "\t 500 images...\n",
      "\t 750 images...\n",
      "\t 1000 images...\n",
      "\t 1124 images!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filepaths_df = create_filepathsdf(path = PATH, n_classes=N_CLASSES, label_classes= LABEL_CLASSES, n_sample=N_SAMPLE)\n",
    "filepaths_df, images = load_imgs(df = filepaths_df)\n",
    "images_sc = preproc_imgs(images = images, img_size = IMG_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split dataset:\n",
      "\t 899 train images; 899 train labels\n",
      "\n",
      "\t 225 test images; 225 test labels\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = create_testtrain(images = images_sc, \\\n",
    "                                                    df = filepaths_df, \\\n",
    "                                                    train_test_split = TRAIN_TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "image_size = x_train[0].shape\n",
    "n_classes = y_train.shape[1]\n",
    "# model = cnn(size=image_size, n_layers=N_LAYERS, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 86\n",
    "\n",
    "img_rows, img_cols = IMG_SIZE\n",
    "\n",
    "nb_filters_1 = 32 \n",
    "nb_filters_2 = 64 \n",
    "nb_filters_3 = 128 \n",
    "\n",
    "nb_conv = 3 # kernel_size dim\n",
    "nb_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 300, 300, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 300, 300, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 150, 150, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 360000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               92160256  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 92,226,338\n",
      "Trainable params: 92,226,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(filters = nb_filters_1, \n",
    "                 kernel_size = (nb_conv,nb_conv),\n",
    "                 padding = 'Same', \n",
    "                 activation ='relu', \n",
    "                 input_shape = image_size))\n",
    "model1.add(Conv2D(filters = nb_filters_1, \n",
    "                 kernel_size = (nb_conv,nb_conv),\n",
    "                 padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Conv2D(filters = nb_filters_2, \n",
    "                 kernel_size = (nb_conv,nb_conv),\n",
    "                 padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model1.add(Conv2D(filters = nb_filters_2, \n",
    "                 kernel_size = (nb_conv,nb_conv),\n",
    "                 padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(256, activation = \"relu\"))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(nb_classes, activation = \"softmax\"))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model1.compile(optimizer = optimizer , \\\n",
    "              loss = \"categorical_crossentropy\", \\\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL TRAINING ##\n",
    "# Training Hyperparamters\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "# Early stopping callback\n",
    "PATIENCE = 10\n",
    "early_stopping = EarlyStopping(monitor='loss', min_delta=0, patience=PATIENCE, verbose=0, mode='auto')\n",
    "\n",
    "# TensorBoard callback\n",
    "LOG_DIRECTORY_ROOT = 'logdir'\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "log_dir = \"{}/run-{}/\".format(LOG_DIRECTORY_ROOT, now)\n",
    "tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, write_images=True)\n",
    "\n",
    "# Place the callbacks in a list\n",
    "callbacks = [early_stopping, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 248s - loss: 4.9234 - acc: 0.4727\n",
      "Epoch 2/5\n",
      " - 228s - loss: 1.2418 - acc: 0.5095\n",
      "Epoch 3/5\n",
      " - 235s - loss: 0.6933 - acc: 0.5006\n",
      "Epoch 4/5\n",
      " - 219s - loss: 0.6928 - acc: 0.5206\n",
      "Epoch 5/5\n",
      " - 211s - loss: 0.6953 - acc: 0.5640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a569fde90>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model1.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,\\\n",
    "          callbacks=callbacks, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "\n",
    "MODEL_DIRECTORY_ROOT = 'modeldir'\n",
    "model_dir = \"{}/run-{}/\".format(MODEL_DIRECTORY_ROOT, now)\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    " \n",
    "save_model(model1, model_dir+'model.h5', overwrite=True,include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL EVALUATION ##\n",
    "# Make a prediction on the test set\n",
    "test_predictions = model1.predict(x_test)\n",
    "test_predictions = np.round(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 300, 300, 3)\n",
      "(225, 2)\n",
      "DescribeResult(nobs=225, minmax=(array([1., 0.], dtype=float32), array([1., 0.], dtype=float32)), mean=array([1., 0.], dtype=float32), variance=array([0., 0.], dtype=float32), skewness=array([0., 0.], dtype=float32), kurtosis=array([-3., -3.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print x_test.shape\n",
    "print test_predictions.shape\n",
    "print stats.describe(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "# Report the accuracy\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run for 30 epochs \n",
    "(see hotdogNhotdog.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Achieved 0.99 Training & 0.64 Test accuracy over 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\n",
    "    \"modeldir/run-20180823035905/model.h5\",\n",
    "    custom_objects=None,\n",
    "    compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-de53ee141956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.4727475023574638,\n",
       "  0.509454945303309,\n",
       "  0.5005561663656266,\n",
       "  0.5205784339262991,\n",
       "  0.5639599475499918],\n",
       " 'loss': [4.923442419431897,\n",
       "  1.2417722793919623,\n",
       "  0.6932877565384972,\n",
       "  0.6927738818894239,\n",
       "  0.6952751575905967]}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
